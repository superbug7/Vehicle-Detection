{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video tracked2_project_video.mp4\n",
      "[MoviePy] Writing video tracked2_project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [19:09<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: tracked2_project_video.mp4 \n",
      "\n",
      "CPU times: user 34min 38s, sys: 5.64 s, total: 34min 44s\n",
      "Wall time: 19min 10s\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from helper_func import *\n",
    "import pickle\n",
    "import random\n",
    "%matplotlib inline\n",
    "# NOTE: the next import is only valid for scikit-learn version <= 0.17\n",
    "# for scikit-learn >= 0.18 use:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "%matplotlib inline\n",
    "# Define a function to extract features from a single image window\n",
    "# This function is very similar to extract_features()\n",
    "# just for a single image rather than list of images\n",
    "def augment_image(img):\n",
    "   new_img = cv2.GaussianBlur(img, (3,3), 0)\n",
    "   #new_img = cv2.cvtColor(new_img, cv2.COLOR_YUV2RGB)\n",
    "   new_img = cv2.cvtColor(new_img, cv2.COLOR_RGB2HSV)\n",
    "   new_img = np.array(new_img, dtype = np.float64)\n",
    "   #Generate new random brightness\n",
    "   random_bright = .5+random.uniform(0.3,1.0)\n",
    "   new_img[:,:,2] = random_bright*new_img[:,:,2]\n",
    "   new_img[:,:,2][new_img[:,:,2]>255]  = 255\n",
    "   new_img = np.array(new_img, dtype = np.uint8)\n",
    "    #Convert back to RGB colorspace\n",
    "   new_img = cv2.cvtColor(new_img, cv2.COLOR_HSV2RGB)\n",
    "   #new_img = cv2.cvtColor(new_img, cv2.COLOR_RGB2YUV)\n",
    "   return new_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read in cars and notcars\n",
    "images = glob.glob('./dataset/*.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in images:\n",
    "    cars.append(image)\n",
    "        \n",
    "images = glob.glob('./dataset_nonv/*.png')\n",
    "for image in images:\n",
    "    notcars.append(image)\n",
    "\n",
    "\n",
    "# Reduce the sample size because\n",
    "# The quiz evaluator times out after 13s of CPU time\n",
    "#sample_size = 500\n",
    "#cars = cars[0:sample_size]\n",
    "#notcars = notcars[0:sample_size]\n",
    "\n",
    "color_space = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 32  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (32, 32) # Spatial binning dimensions\n",
    "hist_bins = 32    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [400, 656] # Min and max in y to search in slide_window()\n",
    "\n",
    "\n",
    "def train_model(cars, notcars):\n",
    "  car_features = extract_features(cars, color_space=color_space, \n",
    "        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "        orient=orient, pix_per_cell=pix_per_cell, \n",
    "        cell_per_block=cell_per_block, \n",
    "        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "  notcar_features = extract_features(notcars, color_space=color_space, \n",
    "        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "        orient=orient, pix_per_cell=pix_per_cell, \n",
    "        cell_per_block=cell_per_block, \n",
    "        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "  X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "  # Fit a per-column scaler\n",
    "  X_scaler = StandardScaler().fit(X)\n",
    "  # Apply the scaler to X\n",
    "  scaled_X = X_scaler.transform(X)\n",
    "\n",
    "  # Define the labels vector\n",
    "  y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "  # Split up data into randomized training and test sets\n",
    "  rand_state = np.random.randint(0, 100)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(\n",
    "      scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "  print('Using:',orient,'orientations',pix_per_cell,\n",
    "      'pixels per cell and', cell_per_block,'cells per block')\n",
    "  print('Feature vector length:', len(X_train[0]))\n",
    "  # Use a linear SVC \n",
    "  svc = LinearSVC()\n",
    "  # Check the training time for the SVC\n",
    "  t=time.time()\n",
    "  svc.fit(X_train, y_train)\n",
    "  t2 = time.time()\n",
    "  print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "  # Check the score of the SVC\n",
    "  print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "  # Check the prediction time for a single sample\n",
    "  t=time.time()\n",
    "  #model = pickle.dump(svc, 'model.pkl')\n",
    "  with open('model.p', 'wb') as f:\n",
    "        pickle.dump((svc, X_scaler), f)\n",
    "\n",
    "  #return svc, X_scaler\n",
    "  #image = mpimg.imread('test1.jpg')\n",
    "  #draw_image = np.copy(image)\n",
    "\n",
    "# Uncomment the following line if you extracted training\n",
    "# data from .png images (scaled 0 to 1 by mpimg) and the\n",
    "# image you are searching is a .jpg (scaled 0 to 255)\n",
    "#image = image.astype(np.float32)/255\n",
    "\n",
    "#windows = slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "#                    xy_window=(96, 96), xy_overlap=(0.5, 0.5))\n",
    "\n",
    "#hot_windows = search_windows(image, windows, svc, X_scaler, color_space=color_space, \n",
    "#                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "#                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "#                        cell_per_block=cell_per_block, \n",
    "#                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "#                        hist_feat=hist_feat, hog_feat=hog_feat)                       \n",
    "\n",
    "#window_img = draw_boxes(draw_image, hot_windows, color=(0, 0, 255), thick=6)                    \n",
    "\n",
    "#plt.imshow(window_img)\n",
    "\n",
    "\n",
    "def find_vehicles_in_frame(image):\n",
    "  ystart = 400\n",
    "  ystop = 656\n",
    "  scale = 1.5\n",
    "  box_list1 = []\n",
    "  box_list2 = []\n",
    "  #image = mpimg.imread('test1.jpg')\n",
    "  svc, X_scaler = pickle.load( open(\"model.p\", \"rb\" ) )\n",
    "  box_list = find_cars(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "  box_list += find_cars(image, 400, 464, 1, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "  box_list += find_cars(image, 416, 480, 1, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "  box_list += find_cars(image, 400, 500, 1.5, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "  box_list += find_cars(image, 430, 530, 1.5, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "  box_list += find_cars(image, 400, 530, 2, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "  box_list += find_cars(image, 430, 560, 2, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "  box_list += find_cars(image, 400, 600, 3.5, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "  box_list += find_cars(image, 464, 656, 3.5, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "\n",
    "\n",
    "  #ystart = 355\n",
    "  #ystop = 550\n",
    "  #scale = 1.5\n",
    "  #box_list2 = find_cars(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "  #box_list = box_list1 + box_list2\n",
    "\n",
    "  heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\n",
    "  # Add heat to each box in box list\n",
    "  heat = add_heat(heat,box_list)\n",
    "\n",
    "  # Apply threshold to help remove false positives\n",
    "  heat = apply_threshold(heat,1)\n",
    "\n",
    "  # Visualize the heatmap when displaying\n",
    "  heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "  # Find final boxes from heatmap using label function\n",
    "  labels = label(heatmap)\n",
    "  #return labels, heatmap\n",
    "  draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "  return draw_img\n",
    "\n",
    "\n",
    "def find_vehicles_in_video(video):\n",
    "    output = \"tracked2_\" + video\n",
    "    input_clip = VideoFileClip(video)\n",
    "    clip = input_clip.fl_image(find_vehicles_in_frame)\n",
    "    #clip = input_clip.fl_image(save_image)\n",
    "    %time clip.write_videofile(output, audio=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "  ystart = 400\n",
    "  ystop = 656\n",
    "  scale = 1.5\n",
    "\n",
    "  ### TRAINING #####\n",
    "  #train_model(cars, notcars)\n",
    "  \n",
    "  ### INFERENCE #####   \n",
    "  #myimage = mpimg.imread('./test1.jpg')\n",
    "  myvid = 'project_video.mp4' \n",
    "  find_vehicles_in_video(myvid)\n",
    "  #new_img =find_vehicles_in_frame(myimage)\n",
    "  #plt.imshow(new_img)\n",
    "  #out_img, box_list = find_cars(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "  \n",
    "  \n",
    "  #heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\n",
    "  # Add heat to each box in box list\n",
    "  #heat = add_heat(heat,box_list)\n",
    "      \n",
    "  # Apply threshold to help remove false positives\n",
    "  #heat = apply_threshold(heat,1)\n",
    "\n",
    "  # Visualize the heatmap when displaying    \n",
    "  #heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "  # Find final boxes from heatmap using label function\n",
    "  #labels = label(heatmap)\n",
    "  #draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "\n",
    "  #fig = plt.figure()\n",
    "  #plt.subplot(121)\n",
    "  #plt.imshow(image)\n",
    "  #plt.title('Original')\n",
    "  #plt.subplot(121)\n",
    "  #plt.imshow(draw_img)\n",
    "  #plt.title('Car Positions')\n",
    "  #plt.subplot(122)\n",
    "  #plt.imshow(heatmap, cmap='hot')\n",
    "  #plt.title('Heat Map')\n",
    "  #fig.tight_layout()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
