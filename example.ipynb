{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD8CAYAAABq6S8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff974243b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "global out_img\n",
    "global firstPass\n",
    "global imgSize\n",
    "global left_fit\n",
    "global right_fit\n",
    "global left_fitx\n",
    "global right_fitx\n",
    "global initialLeftRightFit\n",
    "#last frame's fit lines\n",
    "# variables to remember from first pass\n",
    "initialLeftRightFit = tuple()\n",
    "last_fit = tuple()\n",
    "last_fitx = tuple()\n",
    "#boolean for first pass\n",
    "firstPass = False\n",
    "ploty = np.empty(0)\n",
    "imgSize = tuple()\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "plt.subplots(5,4 )\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "    #print(corners)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        #plt.imshow(img)\n",
    "        #cv2.imshow('img',img)\n",
    "        #cv2.waitKey(500)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And so on and so forth..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-78bc0c8c94ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./camera_cal/calibration1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Performs the camera calibration and image undistortion \n",
    "#while not os.path.isfile(\"../camera_cal/calibration01.jpg\"):\n",
    "    #print('not present')\n",
    "\n",
    "img = cv2.imread('./camera_cal/calibration1.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Undistorit this image\n",
    "def undistort(img):\n",
    "    undist_img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist_img\n",
    "\n",
    "\n",
    "\n",
    "#ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "#print(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def corners_unwarp(img, nx, ny):\n",
    "    h,w = img.shape[:2]\n",
    "    M = cv2.getPerspectiveTransform(nx,ny)\n",
    "    Minv = cv2.getPerspectiveTransform(ny,nx)\n",
    "    warped = cv2.warpPerspective(img,M, (w,h), flags=cv2.INTER_LINEAR)\n",
    "    return warped, M, Minv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that thresholds the S-channel of HLS\n",
    "def hls_select(img, thresh=(200, 235)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    binary_output = np.zeros_like(l_channel)\n",
    "    binary_output[(l_channel > thresh[0]) & (l_channel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LAB_Bthresh(img, thresh=(155,200)):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)\n",
    "    b_channel = lab[:,:,2]\n",
    "    if np.max(b_channel) > 175:\n",
    "       lab_b = b_channel*(255/np.max(b_channel))\n",
    "    # 2) Apply a threshold to the L channel\n",
    "    b_output = np.zeros_like(b_channel)\n",
    "    b_output[((b_channel > thresh[0]) & (b_channel <= thresh[1]))] = 1\n",
    "    return b_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_pipeline(img, s_thresh=(190, 255)):\n",
    "    #img = np.copy(img)\n",
    "    #my_img = cv2.imread('./test_images/test2.jpg')\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #plt.imshow(my_img\n",
    "    #Undistort\n",
    "    h,w = img.shape[:2]\n",
    "    #src1 = np.float32([[(imgSize[1]/4)-50,   imgSize[0]-20],[ imgSize[1]-80,   imgSize[0]-20],[  ((imgSize[1]/2)+140),   (2*imgSize[0]/3)],[  (.4*imgSize[1])-32,   (2*imgSize[0]/3)]])\n",
    "    #dst1 = np.float32([[0,imgSize[0]],[imgSize[1],imgSize[0]],[imgSize[1],0],[0,0]])\n",
    "    #src1 = np.float32(\n",
    "    #[[(img_size[0] / 2) - 55, img_size[1] / 2 + 100],\n",
    "    #[((img_size[0] / 6) - 10), img_size[1]],\n",
    "    ##[(img_size[0] * 5 / 6) + 60, img_size[1]],\n",
    "    #[(img_size[0] / 2 + 55), img_size[1] / 2 + 100]])\n",
    "    #dst1 = np.float32(\n",
    "    #[[(img_size[0] / 4), 0],\n",
    "    #[(img_size[0] / 4), img_size[1]],\n",
    "    #[(img_size[0] * 3 / 4), img_size[1]],\n",
    "    #[(img_size[0] * 3 / 4), 0]])\n",
    "    dst1 = np.float32([(450,0),\n",
    "                 (w-450,0),\n",
    "                 (450,h),\n",
    "                (w-450,h)])\n",
    "    src1 = np.float32([(575,464),\n",
    "                  (707,464), \n",
    "                  (258,682), \n",
    "                  (1049,682)])\n",
    "    #dst1 = np.float32([(450,0),\n",
    "    #              (w-450,0),\n",
    "    #              (450,h),\n",
    "    #              (w-450,h)])\n",
    "    \n",
    "    img_undist = undistort(img)\n",
    "    #Perspective transform \n",
    "    img, M, Minv = corners_unwarp(img_undist,src1,dst1)\n",
    "    \n",
    "    b_binary= LAB_Bthresh(img)\n",
    "    # Threshold color channel\n",
    "    l_binary = hls_select(img)\n",
    "    \n",
    "    color_binary = np.dstack(( np.zeros_like(b_binary), b_binary, l_binary)) * 255\n",
    "    \n",
    "    combined_binary = np.zeros_like(b_binary)\n",
    "    combined_binary[(l_binary == 1) | (b_binary == 1)] = 1\n",
    "    return combined_binary, Minv\n",
    "\n",
    "my_img = cv2.imread('./test_images/test2.jpg')\n",
    "my_img = cv2.cvtColor(my_img, cv2.COLOR_BGR2RGB)\n",
    "#plt.imshow(my_img)    \n",
    "result, Minv = lane_pipeline(my_img)\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "\n",
    "ax1.imshow(my_img)\n",
    "ax1.set_title('Original Image', fontsize=40)\n",
    "\n",
    "ax2.imshow(result)\n",
    "ax2.set_title('Pipeline Result', fontsize=40)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Method to determine radius of curvature and distance from lane center \n",
    "# based on binary image, polynomial fit, and L and R lane pixel indices\n",
    "def calc_radius(bin_img, left_val,right_val): #_fit, r_fit, l_lane_inds, r_lane_inds):\n",
    "    ym_per_pix = 30/720 \n",
    "    xm_per_pix = 3.7/700\n",
    "        \n",
    "    h = bin_img.shape[0]\n",
    "    ploty = np.linspace(0, h-1, h)\n",
    "    y_eval = np.max(ploty)\n",
    "    left_val = left_val[0]*ploty**2 + left_val[1]*ploty + left_val[2]\n",
    "    right_val = right_val[0]*ploty**2 + right_val[1]*ploty + right_val[2]\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    #nonzero = bin_img.nonzero()\n",
    "    #nonzeroy = np.array(nonzero[0])\n",
    "    #nonzerox = np.array(nonzero[1])\n",
    "    # Again, extract left and right line pixel positions\n",
    "    #leftx = nonzerox[l_lane_inds]\n",
    "    #lefty = nonzeroy[l_lane_inds] \n",
    "    #rightx = nonzerox[r_lane_inds]\n",
    "    #righty = nonzeroy[r_lane_inds]\n",
    "    \n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_val*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_val*xm_per_pix, 2)\n",
    "    #right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "        # Calculate the new radii of curvature\n",
    "    left_rad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_rad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "        # Now our radius of curvature is in meters\n",
    "    #return left_curverad\n",
    "    # Distance from center is image x midpoint - mean of l_fit and r_fit intercepts \n",
    "    #if r_fit is not None and l_fit is not None:\n",
    "    car_position = bin_img.shape[1]/2\n",
    "    l_fit_x_int = left_val[0]*h**2 + left_val[1]*h + left_val[2]\n",
    "    r_fit_x_int = right_val[0]*h**2 + right_val[1]*h + right_val[2]\n",
    "    lane_center_position = (r_fit_x_int + l_fit_x_int) /2\n",
    "    center_dist = (car_position - lane_center_position) * xm_per_pix\n",
    "    return left_rad, right_rad, center_dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_lane(original_img, binary_img, l_fit, r_fit, Minv):\n",
    "    h,w = binary_img.shape\n",
    "    ploty = np.linspace(0, h-1, num=h)\n",
    "    #quadratic_coeff = 3e-4\n",
    "    warp_zero = np.zeros_like(binary_img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))*255\n",
    "    \n",
    "    l_fit = l_fit[0]*ploty**2 + l_fit[1]*ploty + l_fit[2]\n",
    "    r_fit = r_fit[0]*ploty**2 + r_fit[1]*ploty + r_fit[2]\n",
    "    \n",
    "    pts_left = np.array([np.transpose(np.vstack([l_fit, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([r_fit, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (original_img.shape[1], original_img.shape[0])) \n",
    "    result = cv2.addWeighted(original_img, 1, newwarp, 0.3, 0)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_text(original_img, curv_rad, center_dist):\n",
    "    new_img = np.copy(original_img)\n",
    "    h = new_img.shape[0]\n",
    "    text = \"radius of curvature: {:.2f}m; distance from center: {:.2f}m\".format(curv_rad, center_dist)\n",
    "    new_img =cv2.putText(new_img, text, (100,100), 2, 1, (200,255,0), 2)\n",
    "    #direction = ''\n",
    "    #if center_dist > 0:\n",
    "    #    direction = 'right'\n",
    "    #elif center_dist < 0:\n",
    "    #    direction = 'left'\n",
    "    #abs_center_dist = abs(center_dist)\n",
    "    #text = '{:04.3f}'.format(abs_center_dist) + 'm ' + direction + ' of center'\n",
    "    #cv2.putText(new_img, text, (40,120), font, 1.5, (200,255,155), 2, cv2.LINE_AA)\n",
    "    return new_img\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global initialLeftRightFit\n",
    "global first_epoch \n",
    "first_epoch = False\n",
    "initialLeftRightFit = tuple()\n",
    "last_fit = tuple()\n",
    "last_fitx = tuple()\n",
    "\n",
    "def pipeline(Img):\n",
    "    global out_img\n",
    "    global first_epoch\n",
    "    global imgSize\n",
    "    global left_fit\n",
    "    global right_fit\n",
    "    global left_fitx\n",
    "    global right_fitx\n",
    "    global initialLeftRightFit\n",
    "    global last_fit\n",
    "    global last_fitx\n",
    "    global ploty\n",
    "    #first_epoch = False\n",
    "    #plt.imshow(Img)\n",
    "    Img = cv2.cvtColor(Img, cv2.COLOR_BGR2RGB)\n",
    "    Img_bin, Minv = lane_pipeline(Img)\n",
    "    Img = undistort(Img)\n",
    "    #left_fit, right_fit, left_lane_inds, right_lane_inds, visualization_data = find_window_centroids(Img_bin)\n",
    "    if not first_epoch:\n",
    "        nonzero = Img_bin.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        out_img = np.dstack((Img_bin,Img_bin, Img_bin))*255\n",
    "        \n",
    "        histogram = np.sum(Img_bin[img.shape[0]//2:,:], axis=0)\n",
    "        midpoint = np.int(histogram.shape[0]//2)\n",
    "        quarter_point = np.int(midpoint//2)\n",
    "        leftx_base = np.argmax(histogram[quarter_point:midpoint]) + quarter_point\n",
    "        rightx_base = np.argmax(histogram[midpoint:(midpoint+quarter_point)]) + midpoint\n",
    "\n",
    "        nwindows = 9\n",
    "        # Set height of windows\n",
    "        window_height = np.int(Img_bin.shape[0]/nwindows)\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        \n",
    "        # Current positions to be updated for each window\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "        # Set the width of the windows +/- margin\n",
    "        margin = 80\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 40\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "        # Rectangle data for visualization\n",
    "        rectangle_data = []\n",
    "\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = Img_bin.shape[0] - (window+1)*window_height\n",
    "            win_y_high = Img_bin.shape[0] - window*window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "            #rectangle_data.append((win_y_low, win_y_high, win_xleft_low, win_xleft_high, win_xright_low, win_xright_high))\n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "        left_fit, right_fit = (None, None)\n",
    "        # Fit a second order polynomial to each\n",
    "        if len(leftx) != 0:\n",
    "            left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        if len(rightx) != 0:\n",
    "            right_fit = np.polyfit(righty, rightx, 2)\n",
    "        last_fit = (left_fit,right_fit) #change\n",
    "        initialLeftRightFit = (left_fit,right_fit) #change\n",
    "\n",
    "        first_epoch= True #change\n",
    "        ploty = np.linspace(0, Img_bin.shape[0]-1, Img_bin.shape[0] )\n",
    "        if len(left_fit) != 0:\n",
    "            left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        if len(right_fit) != 0:\n",
    "            right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        last_fitx = (left_fitx,right_fitx) #change\n",
    "                                   \n",
    "        rad_l, rad_r, d_center = calc_radius(Img_bin, left_fit, right_fit)\n",
    "        result = draw_lane(Img, Img_bin, left_fit, right_fit, Minv)\n",
    "        \n",
    "        \n",
    "    else: #change\n",
    "        nonzero = Img_bin.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        margin = 80 \n",
    " \n",
    "         # Use from first pass\n",
    "        left_fit,right_fit = initialLeftRightFit[0],initialLeftRightFit[1]\n",
    "        margin = 80\n",
    "        left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "        right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "        # Again, extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "        # Fit a second order polynomial to each if every lane has enough pixels to form a lane\n",
    "        if (leftx.size>50)and(lefty.size>50)and(rightx.size>50)and(righty.size>50):\n",
    "\n",
    "            left_fit = np.polyfit(lefty, leftx, 2)\n",
    "            right_fit = np.polyfit(righty, rightx, 2)\n",
    "            last_fit = (left_fit,right_fit)\n",
    "        else:\n",
    "            left_fit, right_fit = last_fit[0], last_fit[1]\n",
    "        # Generate x and y values for plotting\n",
    "        #ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        \n",
    "        # Create an image to draw on and an image to show the selection window\n",
    "        out_img = np.dstack((Img_bin, Img_bin, Img_bin))*255\n",
    "        window_img = np.zeros_like(out_img)\n",
    "        # Color in left and right line pixels\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                      ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                      ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    " \n",
    "    ploty = np.linspace(0, Img_bin.shape[0]-1, Img_bin.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    #rad_l, rad_r, d_center = calc_radius(Img_bin, left_fit, right_fit)\n",
    "    #result = draw_lane(Img, Img_bin, left_fit, right_fit, Minv)\n",
    "\n",
    "    warp_zero = np.zeros_like(Img_bin).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "     # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (Img.shape[1], Img.shape[0])) \n",
    "\n",
    "      # Combine the result with the original image\n",
    "    result = cv2.addWeighted(Img, 1, newwarp, 0.3, 0)    \n",
    "\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    y_eval = np.max(ploty)\n",
    "    midx = 650\n",
    "\n",
    "        ## RADIUS OF CURVATURE\n",
    "    #Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "\n",
    "        # radius of curvature\n",
    "    rad_l = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    rad_r = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "    # in meters\n",
    "    cv2.putText(result,'Radius of Curvature: Left= %.2fm' % rad_l + ',  Right= %.2fm' % rad_r ,(20,40), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2)\n",
    "\n",
    "    left_pixX = left_fit[0]*(y_eval**2) + left_fit[1]*y_eval + left_fit[2]\n",
    "    right_pixX = right_fit[0]*(y_eval**2) + right_fit[1]*y_eval + right_fit[2]\n",
    "    d_center = ((left_pixX + right_pixX)/2 - midx) * xm_per_pix\n",
    "    if d_center < 0:\n",
    "        text = 'left'\n",
    "    else:\n",
    "        text = 'right'\n",
    "    cv2.putText(result,'Distance From Center: %.2fm %s' % (np.absolute(d_center), text),(20,80), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2)                               \n",
    "                                   \n",
    "                                   \n",
    "    #img_draw = print_text(Img_out1, (rad_l+rad_r)/2, d_center)\n",
    "    return result\n",
    "    #draw_data(original_img, curv_rad, center_dist)\n",
    "#Img = cv2.imread('./test_images/test2.jpg')\n",
    "#final_img = pipeline(Img) \n",
    "#plt.imshow(final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(first_epoch)\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "source = VideoFileClip(\"./project_video.mp4\")#.subclip(20, 25)\n",
    "target = \"project_video_output.mp4\"\n",
    "\n",
    "annotated = source.fl_image(pipeline)\n",
    "%time annotated.write_videofile(target, audio=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
